{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oaGGhdmYKqt"
      },
      "source": [
        "# 패키지 설치\n",
        "pip 명령어로 의존성 있는 패키지를 설치합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8TJkXkpDnSq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'#pip'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        }
      ],
      "source": [
        "!#pip install ratsnlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFt_JLYoTKA6"
      },
      "source": [
        "## 토크나이저 초기화\n",
        "\n",
        "BERT(`kcbert-base`) 모델이 쓰는 토크나이저를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bThW-2OrTHZW"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3d6d1ad580a46a68fd461f76f552c50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/250k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3c34c798fba4e948709f067935f9fdf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24d779be557d4db8b5647c52d60932a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    do_lower_case=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0NCnzpRTdnJ"
      },
      "source": [
        "## 모델 초기화\n",
        "\n",
        "BERT(`kcbert-base`) 모델을 읽어들입니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FSVDbnFUTiXx"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6160555ccf844379b91ed35eecb14aa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    \"beomi/kcbert-base\"\n",
        ")\n",
        "model = BertModel.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    config=pretrained_model_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWboOauTTyXp"
      },
      "source": [
        "`pretrained_model_config`의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tup5LreLT4vE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"beomi/kcbert-base\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 300,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.10.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30000\n",
              "}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrained_model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y2JYqRGUFll"
      },
      "source": [
        "## 모델 입력값 만들기\n",
        "\n",
        "문장 2개를 모델 입력값으로 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9Rk2Ga65USFb"
      },
      "outputs": [],
      "source": [
        "sentences = [\"안녕하세요\", \"하이!\"]\n",
        "features = tokenizer(\n",
        "    sentences,\n",
        "    max_length=10,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLq1JRVJUb7U"
      },
      "source": [
        "`features`의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XZl8OKdsVIQg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LzkJ31vQVbjl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2, 19017, 8482, 3, 0, 0, 0, 0, 0, 0], [2, 15830, 5, 3, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lc_71OjafQgS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fdv1TGOHfQpm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features['token_type_ids']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR-3V6zIVsPp"
      },
      "source": [
        "## BERT 임베딩 추출\n",
        "\n",
        "위에서 만든 `features`를 파이토치 텐서(tensor)로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FdvUPuJoV3w3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "features = {k: torch.tensor(v) for k, v in features.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0S2EbdkWIdq"
      },
      "source": [
        "BERT 모델에 `features`를 입력해 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YOWkywHaWOL6"
      },
      "outputs": [],
      "source": [
        "outputs = model(**features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fog_9z0SqHog"
      },
      "source": [
        "BERT 마지막 레이어의 단어 수준 벡터들을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-wRQNlJMqMjh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.6969, -0.8248,  1.7512,  ..., -0.3732,  0.7399,  1.1907],\n",
              "         [-1.4803, -0.4398,  0.9444,  ..., -0.7405, -0.0211,  1.3064],\n",
              "         [-1.4299, -0.5033, -0.2069,  ...,  0.1285, -0.2611,  1.6057],\n",
              "         ...,\n",
              "         [-1.4406,  0.3431,  1.4043,  ..., -0.0565,  0.8450, -0.2170],\n",
              "         [-1.3625, -0.2404,  1.1757,  ...,  0.8876, -0.1054,  0.0734],\n",
              "         [-1.4244,  0.1518,  1.2920,  ...,  0.0245,  0.7572,  0.0080]],\n",
              "\n",
              "        [[ 0.9371, -1.4749,  1.7351,  ..., -0.3426,  0.8050,  0.4031],\n",
              "         [ 1.6095, -1.7269,  2.7936,  ...,  0.3100, -0.4787, -1.2491],\n",
              "         [ 0.4861, -0.4569,  0.5712,  ..., -0.1769,  1.1253, -0.2756],\n",
              "         ...,\n",
              "         [ 1.2362, -0.6181,  2.0906,  ...,  1.3677,  0.8132, -0.2742],\n",
              "         [ 0.5409, -0.9652,  1.6237,  ...,  1.2395,  0.9185,  0.1782],\n",
              "         [ 1.9001, -0.5859,  3.0156,  ...,  1.4967,  0.1924, -0.4448]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwDi0WNdrG7r"
      },
      "source": [
        "BERT 마지막 레이어의 문서 수준 벡터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0FQ1nayZrLQl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1594,  0.0547,  0.1101,  ...,  0.2684,  0.1596, -0.9828],\n",
              "        [-0.9221,  0.2969, -0.0110,  ...,  0.4291,  0.0311, -0.9955]],\n",
              "       grad_fn=<TanhBackward0>)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.pooler_output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('crp-yolo')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "85655d326657acff456c3f00d35448c6c67e6a1f13b4085d359f5fec2477f390"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
